"""LangGraph HTTP API æœåŠ¡

è¿™ä¸ªæ¨¡å—æä¾›äº†ä¸€ä¸ªHTTP APIæœåŠ¡ï¼Œå°è£…LangGraphä»£ç†è°ƒç”¨ã€‚
å¯¹å¤–æš´éœ²REST APIæ¥å£ï¼Œä¾›å‰ç«¯æˆ–å…¶ä»–æœåŠ¡è°ƒç”¨ã€‚
"""

import asyncio
import json
import os
from typing import Dict, Any, Optional, List
from datetime import datetime

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from langgraph_sdk import get_client


# è¯·æ±‚å’Œå“åº”æ¨¡å‹
class ChatMessage(BaseModel):
    """èŠå¤©æ¶ˆæ¯æ¨¡å‹"""
    role: str = Field(..., description="æ¶ˆæ¯è§’è‰²: human, assistant, system")
    content: str = Field(..., description="æ¶ˆæ¯å†…å®¹")


class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚æ¨¡å‹"""
    message: str = Field(..., description="ç”¨æˆ·æ¶ˆæ¯", min_length=1, max_length=2000)
    thread_id: Optional[str] = Field(None, description="çº¿ç¨‹IDï¼Œç”¨äºå¤šè½®å¯¹è¯")
    model: Optional[str] = Field(None, description="æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹")


class ChatResponse(BaseModel):
    """èŠå¤©å“åº”æ¨¡å‹"""
    success: bool = Field(..., description="è¯·æ±‚æ˜¯å¦æˆåŠŸ")
    message: str = Field(..., description="å“åº”æ¶ˆæ¯")
    data: Optional[Dict[str, Any]] = Field(None, description="å“åº”æ•°æ®")
    thread_id: Optional[str] = Field(None, description="çº¿ç¨‹ID")
    timestamp: str = Field(..., description="å“åº”æ—¶é—´æˆ³")


class HealthResponse(BaseModel):
    """å¥åº·æ£€æŸ¥å“åº”æ¨¡å‹"""
    status: str = Field(..., description="æœåŠ¡çŠ¶æ€")
    timestamp: str = Field(..., description="æ£€æŸ¥æ—¶é—´")
    version: str = Field(..., description="æœåŠ¡ç‰ˆæœ¬")


# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="LangGraph API Service",
    description="åŸºäºLangGraphçš„AIä»£ç†HTTP APIæœåŠ¡",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
langgraph_client = None


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–LangGraphå®¢æˆ·ç«¯"""
    global langgraph_client
    langgraph_url = os.getenv("LANGGRAPH_API_URL", "http://localhost:2024")
    langgraph_client = get_client(url=langgraph_url)
    print(f"ğŸš€ LangGraph HTTP API æœåŠ¡å¯åŠ¨")
    print(f"ğŸ“¡ è¿æ¥åˆ° LangGraph æœåŠ¡å™¨: {langgraph_url}")


@app.get("/", response_model=HealthResponse)
async def root():
    """æ ¹è·¯å¾„å¥åº·æ£€æŸ¥"""
    return HealthResponse(
        status="healthy",
        timestamp=datetime.now().isoformat(),
        version="1.0.0"
    )


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return HealthResponse(
        status="healthy",
        timestamp=datetime.now().isoformat(),
        version="1.0.0"
    )


@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """èŠå¤©æ¥å£
    
    å‘é€æ¶ˆæ¯åˆ°LangGraphä»£ç†å¹¶è·å–å“åº”
    """
    try:
        if not langgraph_client:
            raise HTTPException(status_code=500, detail="LangGraphå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
        print(f"ğŸ“¨ æ”¶åˆ°èŠå¤©è¯·æ±‚: {request.message}")
        print(f"ğŸ§µ çº¿ç¨‹ID: {request.thread_id or 'æ–°çº¿ç¨‹'}")
        
        # æ„å»ºæ¶ˆæ¯æ ¼å¼
        messages = [{
            "role": "human",
            "content": request.message,
        }]
        
        # è°ƒç”¨LangGraphä»£ç†
        response_data = []
        final_message = ""
        current_thread_id = request.thread_id
        
        async for chunk in langgraph_client.runs.stream(
            request.thread_id,  # ä½¿ç”¨æä¾›çš„çº¿ç¨‹IDæˆ–åˆ›å»ºæ–°çº¿ç¨‹
            "agent",  # ä»£ç†åç§°
            input={"messages": messages},
        ):
            if chunk.event == "messages":
                # å¤„ç†æ¶ˆæ¯å“åº”
                for msg in chunk.data.get("messages", []):
                    if msg.get("role") == "assistant":
                        final_message = msg.get("content", "")
                        response_data.append({
                            "type": "message",
                            "content": final_message,
                            "role": "assistant"
                        })
            
            elif chunk.event == "tools":
                # å¤„ç†å·¥å…·è°ƒç”¨
                response_data.append({
                    "type": "tool_call",
                    "data": chunk.data
                })
                print(f"ğŸ”§ å·¥å…·è°ƒç”¨: {chunk.data}")
            
            elif chunk.event == "end":
                # è·å–çº¿ç¨‹ID
                if hasattr(chunk, 'thread_id'):
                    current_thread_id = chunk.thread_id
                break
        
        return ChatResponse(
            success=True,
            message="èŠå¤©è¯·æ±‚å¤„ç†æˆåŠŸ",
            data={
                "response": final_message,
                "full_data": response_data,
                "model_used": request.model or "default"
            },
            thread_id=current_thread_id,
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        print(f"âŒ èŠå¤©è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"èŠå¤©è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}"
        )


@app.get("/api/threads")
async def get_threads():
    """è·å–æ‰€æœ‰çº¿ç¨‹åˆ—è¡¨"""
    try:
        if not langgraph_client:
            raise HTTPException(status_code=500, detail="LangGraphå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
        threads = await langgraph_client.threads.list()
        return {
            "success": True,
            "data": threads,
            "message": "è·å–çº¿ç¨‹åˆ—è¡¨æˆåŠŸ",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ è·å–çº¿ç¨‹åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"è·å–çº¿ç¨‹åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


@app.delete("/api/threads/{thread_id}")
async def delete_thread(thread_id: str):
    """åˆ é™¤æŒ‡å®šçº¿ç¨‹"""
    try:
        if not langgraph_client:
            raise HTTPException(status_code=500, detail="LangGraphå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„SDKæ–¹æ³•æ¥å®ç°
        # await langgraph_client.threads.delete(thread_id)
        
        return {
            "success": True,
            "message": f"çº¿ç¨‹ {thread_id} åˆ é™¤æˆåŠŸ",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ åˆ é™¤çº¿ç¨‹å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"åˆ é™¤çº¿ç¨‹å¤±è´¥: {str(e)}"
        )


@app.get("/api/models")
async def get_available_models():
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    return {
        "success": True,
        "data": {
            "models": [
                "openai/gpt-4o-mini",
                "openai/gpt-4-turbo-preview", 
                "anthropic/claude-3-5-sonnet-20240620",
                "anthropic/claude-3-haiku-20240307"
            ],
            "default": "openai/gpt-4o-mini"
        },
        "message": "è·å–æ¨¡å‹åˆ—è¡¨æˆåŠŸ",
        "timestamp": datetime.now().isoformat()
    }


if __name__ == "__main__":
    import uvicorn
    
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    host = os.getenv("API_HOST", "0.0.0.0")
    port = int(os.getenv("API_PORT", "8000"))
    
    print(f"ğŸŒ å¯åŠ¨HTTP APIæœåŠ¡")
    print(f"ğŸ“ æœåŠ¡åœ°å€: http://{host}:{port}")
    print(f"ğŸ“š APIæ–‡æ¡£: http://{host}:{port}/docs")
    
    uvicorn.run(
        "http_service:app",
        host=host,
        port=port,
        reload=True,
        log_level="info"
    )
